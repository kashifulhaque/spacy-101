{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Combining predictions and rules**\n",
    "\n",
    "|                         | Statistical models                                | Rule-based systems                               |\n",
    "|-------------------------|---------------------------------------------------|--------------------------------------------------|\n",
    "| **Use cases**           | application needs to generalize based on examples | dictionary with finite number of examples        |\n",
    "| **Real-world examples** | product & person names, subject/object relations  | countries of the world, cities, drug names, etc. |\n",
    "| **spaCy features**      | entity recognition, dependency parser, pos tagger | tokenizer, `Matcher`, `PhraseMatcher`            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What rule-based matching looked like**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize with the shared vocab\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patterns are lists of dictionaries describing the tokens\n",
    "pattern = [\n",
    "  { \"LEMMA\": \"love\" },\n",
    "  { \"POS\": \"VERB\" },\n",
    "  { \"LOWER\": \"cats\" }\n",
    "]\n",
    "matcher.add(\"LOVE_CATS\", [pattern])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operators can specify how often a token should be matched\n",
    "pattern = [\n",
    "  { \"TEXT\": \"very\" },\n",
    "  { \"OP\": \"+\" },\n",
    "  { \"TEXT\": \"happy\" }\n",
    "]\n",
    "matcher.add(\"VERY_HAPPY\", [pattern])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"I love cats and I'm very very happy\")\n",
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches: ['very very happy']\n"
     ]
    }
   ],
   "source": [
    "print(\"Matches:\", [doc[start:end].text for match_id, start, end in matches])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding statistical predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched span: Golden Retriever\n",
      "Root token: Retriever\n",
      "Root head token: have\n",
      "Previous token: a DET\n"
     ]
    }
   ],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"DOG\", [[{ \"LOWER\": \"golden\" }, { \"LOWER\": \"retriever\" }]])\n",
    "doc = nlp(\"I have a Golden Retriever\")\n",
    "\n",
    "for match_id, start, end in matcher(doc):\n",
    "  span = doc[start:end]\n",
    "  print(\"Matched span:\", span.text)\n",
    "\n",
    "  # Get the span's root token and root head token\n",
    "  print(\"Root token:\", span.root.text)\n",
    "  print(\"Root head token:\", span.root.head.text)\n",
    "\n",
    "  # Get the previous token and its POS tag\n",
    "  print(\"Previous token:\", doc[start - 1].text, doc[start - 1].pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Efficient phrase matching**\n",
    "\n",
    "- `PhraseMatcher` like regex or keyword search - but with access to the tokens\n",
    "  - Helpful tool in finding sequences of words in data\n",
    "- Takes `Doc` object as patterns\n",
    "- More efficient and faster than the `Matcher`\n",
    "- Great for matching large word lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "matcher = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = nlp(\"Golden Retriever\")\n",
    "matcher.add(\"DOG\", [pattern])\n",
    "doc = nlp(\"I have a Golden Retriever\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched span: Golden Retriever\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the matches\n",
    "for match_id, start, end in matcher(doc):\n",
    "  # Get the matched span\n",
    "  span = doc[start:end]\n",
    "  print(\"Matched span:\", span.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
